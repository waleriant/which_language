{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2fe256a4-c441-4a84-a2a9-1b6b7d6de4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc38028c-c761-4e41-9d6c-c82d52a2f981",
   "metadata": {},
   "source": [
    "#### Extract all the \"interlanguage\" URLs of a popular Wikipedia page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8112af67-ccbe-4d39-8ab0-b439ecbfc497",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://fr.wikipedia.org/wiki/France\")\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f1e7ff8b-1d5d-4e03-86bc-716f2d86b0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "for line in soup.find_all(\"li\"):\n",
    "     if line.get(\"class\") != None:\n",
    "        if 'interlanguage-link' in line.get(\"class\"):\n",
    "            url = line.find(\"a\").get(\"href\")\n",
    "            urls.append(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f03ff7-9fff-4e8d-bd09-87527b265b49",
   "metadata": {},
   "source": [
    "#### Adapt each one of these URLs to build a Wikipedia's random page link for the language concerned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3a599f23-968e-43cf-8530-e1a0be484620",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_urls = []\n",
    "for url in urls:\n",
    "    position = url.find(\"/wiki/\")\n",
    "    new_urls.append(f\"{url[:position + len(\"/wiki/\")]}Special:Random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba3ae6d-23b7-47b3-ace6-c5c58b0a4328",
   "metadata": {},
   "source": [
    "#### Extract the language names related to these pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2ca9f6c5-172d-4f1c-827e-71e7217fdd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "for line in soup.find_all(\"a\"):\n",
    "     if line.get(\"class\") != None:\n",
    "        if 'interlanguage-link-target' in line.get(\"class\"):\n",
    "            name = line.get(\"data-language-autonym\")\n",
    "            names.append(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba96686c-18fe-4e9b-bd76-657f19955e01",
   "metadata": {},
   "source": [
    "#### Let's use ChatGPT to translate all these language names in English!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fdb0dab0-0da5-4cb3-a1ad-2b61afb38bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_tr = ['Abkhazian', 'Acehnese', 'Adyghe', 'Afrikaans', 'Alemannic', 'Amharic', 'Pangcah', 'Aragonese', 'Old English', 'Angika', 'Arabic', 'Aramaic', 'Darija', 'Egyptian Arabic', 'Assamese', 'Asturian', 'Atikamekw', 'Avar', 'Kotava', 'Awadhi', 'Aymara', 'Azerbaijani', 'South Azerbaijani', 'Bashkir', 'Balinese', 'Bavarian', 'Samogitian', 'Batak Toba', 'Central Bikol', 'Belarusian', 'Belarusian (Taraškievica)', 'Betawi', 'Bulgarian', 'Bhojpuri', 'Bislama', 'Banjar', 'Pa’O Karen', 'Bambara', 'Bengali', 'Tibetan', 'Bishnupriya Manipuri', 'Breton', 'Bosnian', 'Batak Mandailing', 'Buginese', 'Buryat', 'Catalan', 'Chavacano of Zamboanga', 'Eastern Min', 'Chechen', 'Cebuano', 'Chamorro', 'Cherokee', 'Cheyenne', 'Kurmanji', 'Corsican', 'Crimean Tatar', 'Czech', 'Kashubian', 'Old Church Slavonic', 'Chuvash', 'Welsh', 'Danish', 'Dagbani', 'German', 'Zazaki', 'Lower Sorbian', 'Dusun Bundu-liwan', 'Doteli', 'Dhivehi', 'Dzongkha', 'Ewe', 'Greek', 'Emilian-Romagnol', 'English', 'Esperanto', 'Spanish', 'Estonian', 'Basque', 'Extremaduran', 'Persian', 'Fula', 'Finnish', 'Võro', 'Fijian', 'Faroese', 'Fon', 'Franco-Provençal', 'North Frisian', 'Friulian', 'Western Frisian', 'Irish', 'Gagauz', 'Gan Chinese', 'Guianese Creole', 'Scottish Gaelic', 'Galician', 'Gilaki', 'Guarani', 'Goan Konkani', 'Gothic', 'Gujarati', 'Manx', 'Hausa', 'Hakka Chinese', 'Hawaiian', 'Hebrew', 'Hindi', 'Fiji Hindi', 'Croatian', 'Upper Sorbian', 'Haitian Creole', 'Hungarian', 'Armenian', 'Western Armenian', 'Interlingua', 'Indonesian', 'Interlingue', 'Igbo', 'Ilocano', 'Ingush', 'Ido', 'Icelandic', 'Italian', 'Inuktitut', 'Japanese', 'Jamaican Patois', 'Lojban', 'Javanese', 'Georgian', 'Karakalpak', 'Kabyle', 'Adyghe', 'Kabiye', 'Tyap', 'Kongo', 'Kumoring', 'Kikuyu', 'Kazakh', 'Khmer', 'Kannada', 'Korean', 'Komi-Permyak', 'Karachay-Balkar', 'Ripuarian', 'Kurmanji', 'Komi', 'Cornish', 'Kyrgyz', 'Latin', 'Ladino', 'Luxembourgish', 'Lezgi', 'Lingua Franca Nova', 'Luganda', 'Limburgish', 'Ligurian', 'Ladin', 'Lombard', 'Lingala', 'Lao', 'Lithuanian', 'Latgalian', 'Latvian', 'Madurese', 'Maithili', 'Banyumasan', 'Moksha', 'Malagasy', 'Meadow Mari', 'Māori', 'Minangkabau', 'Macedonian', 'Malayalam', 'Mongolian', 'Meitei', 'Marathi', 'Malay', 'Maltese', 'Mirandese', 'Burmese', 'Erzya', 'Mazandarani', 'Neapolitan', 'Low German', 'Low Saxon', 'Nepali', 'Newar', 'Dutch', 'Norwegian Nynorsk', 'Norwegian Bokmål', 'Novial', 'N’Ko', 'Norman', 'Northern Sotho', 'Navajo', 'Chichewa', 'Occitan', 'Livvi-Karelian', 'Oromo', 'Ossetian', 'Punjabi', 'Pangasinan', 'Kapampangan', 'Papiamento', 'Picard', 'Pennsylvania Dutch', 'Palatine German', 'Pali', 'Norfuk / Pitkern', 'Polish', 'Piedmontese', 'Punjabi (Shahmukhi)', 'Pontic Greek', 'Pashto', 'Portuguese', 'Quechua', 'Romansh', 'Romani', 'Kirundi', 'Romanian', 'Aromanian', 'Tarandíne', 'Russian', 'Rusyn', 'Kinyarwanda', 'Sanskrit', 'Sakha', 'Santali', 'Sardinian', 'Sicilian', 'Scots', 'Sindhi', 'Northern Sami', 'Sango', 'Serbo-Croatian', 'Tachelhit', 'Shan', 'Sinhala', 'Simple English', 'Slovak', 'Saraiki', 'Slovenian', 'Samoan', 'Skolt Sami', 'Shona', 'Somali', 'Albanian', 'Serbian', 'Sranan Tongo', 'Swazi', 'Sotho', 'Saterland Frisian', 'Sundanese', 'Swedish', 'Swahili', 'Silesian', 'Sakizaya', 'Tamil', 'Tayal', 'Telugu', 'Tetum', 'Tajik', 'Thai', 'Tigrinya', 'Turkmen', 'Tagalog', 'Talysh', 'Tswana', 'Tongan', 'Tok Pisin', 'Turkish', 'Seediq', 'Tsonga', 'Tatar', 'Tumbuka', 'Twi', 'Tahitian', 'Tuvan', 'Udmurt', 'Uyghur', 'Ukrainian', 'Urdu', 'Uzbek', 'Venetian', 'Veps', 'Vietnamese', 'West Flemish', 'Volapük', 'Walloon', 'Waray', 'Wolof', 'Wu Chinese', 'Kalmyk', 'Xhosa', 'Mingrelian', 'Yiddish', 'Yoruba', 'Zhuang', 'Zeelandic', 'Tachelhit', 'Chinese', 'Classical Chinese', 'Hokkien', 'Cantonese', 'Zulu']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626f5746-db67-4cae-bb91-599b5578d5d1",
   "metadata": {},
   "source": [
    "#### Create a list of dictionaries. Each one consists in a language name and the URL of the related Wikipedia's random page. Create a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bda655a1-e9b1-426f-822f-18d543016011",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = []\n",
    "for i in range(len(names_tr)):\n",
    "    my_list.append({\"language\": names_tr[i], \"url\": new_urls[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1355c761-418c-4d83-9532-aee878105479",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"webscraping.json\",\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(my_list, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
